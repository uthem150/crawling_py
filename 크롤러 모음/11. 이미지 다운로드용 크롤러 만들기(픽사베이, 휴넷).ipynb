{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. 이미지 다운로드용 웹크롤러 만들기\n",
    "# Step 1. 필요한 모듈과 라이브러리를 로딩하고 검색어를 입력 받습니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 휴넷 사이트의 강의 자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(예: 파이썬): ')\n",
    "\n",
    "try :\n",
    "    cnt = int( input('2.수집할 건수는 총 몇건입니까?(기본값:10): '))\n",
    "except ValueError :\n",
    "    cnt = 10\n",
    "    print('기본값인 10 건으로 수집을 진행합니다.')\n",
    "page_cnt = math.ceil( cnt / 12)\n",
    "\n",
    "f_dir=input('3.파일이 저장될 경로만 쓰세요(예: c:\\\\py_temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"c:\\\\py_temp\\\\\"\n",
    "\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "url = 'https://www.hunet.co.kr/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element(By.ID,'txtKeyword')\n",
    "driver.find_element(By.ID,'txtKeyword').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "#Step 5. 사용자가 요청한 건수만큼 더보기 클릭하기\n",
    "for a in range(0,page_cnt) :\n",
    "    try :\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"divEducationList\"]/div/div[2]/div[5]/a[1]').click()\n",
    "        time.sleep(2)\n",
    "        try :\n",
    "            result = driver.switch_to_alert()\n",
    "            result.accept( )\n",
    "        except :\n",
    "            continue\n",
    "    except :\n",
    "        print('페이지 이동이 끝났습니다. 이제 데이터를 수집하겠습니다')\n",
    "        break\n",
    "    \n",
    "# Step 6. 이미지 추출하여 저장하기 \n",
    "file_no = 0                                \n",
    "count = 1\n",
    "img_src2=[]  # 이미지 원본 URL 주소 저장할 리스트\n",
    "\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "img_src = soup.find('ul','vod_list').find_all('img')\n",
    "\n",
    "for i in img_src :\n",
    "    img_src1=i['src']\n",
    "    img_src2.append(img_src1)\n",
    "    print(img_src1)\n",
    "    count += 1\n",
    "    if count > cnt :\n",
    "        break\n",
    "\n",
    "for i in range(0,len(img_src2)) :\n",
    "    file_no += 1 \n",
    "    urllib.request.urlretrieve(urllib.parse.quote(img_src2[i].encode('utf8'), '/:'),str(file_no)+'.jpg')\n",
    "\n",
    "    time.sleep(0.5)      \n",
    "    print(\"%s 번째 이미지 저장중입니다=======\" %file_no)\n",
    "\n",
    "# Step 7. 요약 정보를 출력합니다                \n",
    "print(\"=\" *70)\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %file_no)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2. pixapay 사이트에서 그림 수집하기\n",
    "# Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "#Step 2. 필요한 정보를 입력 받습니다.\n",
    "print(\"=\" *80)\n",
    "print(\" pixabay 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다 \")\n",
    "print(\"=\" *80)\n",
    "\n",
    "query_txt = input('1.크롤링할 이미지의 키워드는 무엇입니까?: ')\n",
    "cnt = int(input('2.크롤링 할 건수는 몇건입니까?: '))\n",
    "real_cnt = math.ceil(cnt / 100) # 실제 크롤링 할 페이지 수\n",
    "f_dir=input('3.파일이 저장될 경로만 쓰세요(예: c:\\\\py_temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"c:\\\\py_temp\\\\\"\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 수집 중이오니 잠시만 기다려 주세요~~^^\")\n",
    "\n",
    "#Step 3. 파일을 저장할 폴더를 생성합니다\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)      \n",
    "\n",
    "#Step 4. 크롬 드라이버를 사용해서 웹 브라우저를 실행한 후 검색합니다\n",
    "s_time = time.time( )\n",
    "\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get('https://pixabay.com/ko/')\n",
    "time.sleep(3)\n",
    "\n",
    "# 검색어 입력 창에 검색어 입력 후 검색 수행\n",
    "element = driver.find_element(By.XPATH,'//*[@id=\"hero\"]/div[4]/form/div/span/input')\n",
    "element.send_keys(query_txt)\n",
    "element.submit()\n",
    "\n",
    "# Step 5. 이미지 추출하여 저장하기 \n",
    "file_no = 1\n",
    "count = 1\n",
    "img_src2=[]    #이미지 파일의 url 주소 저장용 리스트\n",
    "\n",
    "# 스크롤 다운 함수 만들기\n",
    "def scroll_down(driver):\n",
    "    #driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(1)\n",
    "\n",
    "for a in range(1 , real_cnt+1):  \n",
    "    \n",
    "    for b in range(0,5):\n",
    "        scroll_down(driver)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # 원본 이미지 url 주소 수집 \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')    \n",
    "    img_src = soup.find('div','row-masonry search-results').find_all('img')\n",
    "   \n",
    "    for c in img_src :\n",
    "        img_src1=c['src']\n",
    "        \n",
    "        if 'http' in img_src1 :\n",
    "            img_src2.append(img_src1)\n",
    "            print(img_src1)\n",
    "            \n",
    "        count += 1  \n",
    "        \n",
    "        if count > cnt :\n",
    "            break\n",
    "            \n",
    "    #수집된 url 주소로 이미지 파일 가져와서 저장하기\n",
    "    for e in range(0,len(img_src2)) :\n",
    "\n",
    "        class AppURLopener(urllib.request.FancyURLopener):\n",
    "            version = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                       Chrome/47.0.2526.69 Safari/537.36\"\n",
    "\n",
    "        urllib.urlopener = AppURLopener()\n",
    "        urllib.urlopener.retrieve(img_src2[e],str(file_no)+'.jpg')\n",
    "\n",
    "        print(\"%s 페이지에서 %s 번째 이미지 저장중입니다=======\" %(a,file_no))\n",
    "\n",
    "        time.sleep(0.5) \n",
    "\n",
    "        if file_no >= cnt :\n",
    "                break\n",
    "\n",
    "        file_no += 1  \n",
    "                \n",
    "    if a > real_cnt :\n",
    "        break\n",
    "\n",
    "# Step 6. 요약 정보를 출력합니다                \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *70)\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %file_no)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
