{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 블로그 정보 수집하여 저장하기\n",
    "\n",
    "print(\"=\" *80)\n",
    "print(\" 네이버 VIEW - 저장할 내용을 목록으로 만들어서 xls , csv 형식으로 저장하기\")\n",
    "print(\"=\" *80)\n",
    "\n",
    "#Step 0. 필요한 모듈과 라이브러리를 로딩하고 검색어를 입력 받습니다\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys        # system 설정을 변경하기 위해 필요합니다\n",
    "import math\n",
    "import pandas  as pd   \n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "query_txt = input('1.크롤링할 키워드는 무엇입니까?: ')\n",
    "cnt=int(input('2.수집할 데이터는 몇 건입니까?: ') )\n",
    "page_cnt = math.ceil(cnt / 30)\n",
    "\n",
    "f_dir = input('3.결과를 저장할 폴더이름을 입력해주세요(기본경로: c:\\\\py_temp\\\\) :')\n",
    "if f_dir =='' :\n",
    "    f_dir = 'c:\\\\py_temp\\\\'\n",
    "    \n",
    "#Step 1. 크롬 드라이버를 사용해서 웹 브라우저를 실행합니다.\n",
    "# import chromedriver_autoinstaller\n",
    "# chromedriver_autoinstaller.install()\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get('http://www.naver.com')\n",
    "time.sleep(1)\n",
    "\n",
    "#Step 2. 네이버 검색창에 입력 받은 검색어를 넣고 검색한 후 \"블로그\" 선택\n",
    "element = driver.find_element(By.ID ,\"query\")\n",
    "element.send_keys(query_txt)\n",
    "element.submit()\n",
    "\n",
    "driver.find_element(By.LINK_TEXT,\"VIEW\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.find_element(By.LINK_TEXT,\"블로그\").click()\n",
    "\n",
    "# Step 9. 저장 목록을 만든 후 목록에 있는 내용을 파일에 저장하기\n",
    "\n",
    "no2 = [ ]           # 게시글 번호 컬럼\n",
    "title2 = [ ]        # 게시물 제목 컬럼\n",
    "contents2 = [ ]     # 게시글 내용 컬럼\n",
    "bdate2 = [ ]        # 작성 일자 컬럼\n",
    "nick2 = [ ]         # 블로그 닉네임\n",
    "writer2 =[ ]        # 작성자\n",
    "\n",
    "#Step 5. 현재 페이지의 내용을 저장 목록을 만든 후 목록에 있는 내용을 파일에 저장하기\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "  driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "  time.sleep(1)\n",
    "\n",
    "if page_cnt >= 2 :\n",
    "    i = 1\n",
    "    while (i < page_cnt + 1):\n",
    "        scroll_down(driver) \n",
    "        i += 1\n",
    "        print('%s 페이지 정보를 추출하고 있으니 잠시만 기다려 주세요~~^^' %i)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "view_list = soup.find('ul','lst_view _list_base').find_all('li')\n",
    "\n",
    "no = 1\n",
    "\n",
    "for i in view_list :\n",
    "    \n",
    "    no2.append(no)                            # 게시물 번호 리스트에 추가\n",
    "    print('1.번호:',no)\n",
    "\n",
    "    title = i.find('div','title_area').find('a').get_text( ) \n",
    "    #title = all_title[5].get_text( )          # 게시물 제목\n",
    "    title2.append(title)                      # 게시물 제목 리스트에 추가\n",
    "    print('2.제목:',title)\n",
    "\n",
    "    writer = i.find('div','user_info').find('a').get_text( ) \n",
    "    #writer = all_title[4].get_text( )          # 게시물 작성자\n",
    "    writer2.append(writer)                      # 게시물 작성자 리스트에 추가\n",
    "    print('3.작성자:',writer)\n",
    "\n",
    "    \n",
    "    try :\n",
    "        contents = i.find('div' , 'dsc_area').get_text( )   # 게시물 내용\n",
    "    except :\n",
    "        contents = '본문 요약 내용이 없습니다'\n",
    "        contents2.append(contents)                # 게시물 내용 리스트에 추가\n",
    "        print('4.요약내용:',contents)\n",
    "    else :\n",
    "        contents2.append(contents)                # 게시물 내용 리스트에 추가\n",
    "        print('4.요약내용:',contents)\n",
    "\n",
    "    bdate = i.find('span','sub').get_text( )  # 작성일자\n",
    "    bdate2.append(bdate)                     # 작성일자 리스트에 추가\n",
    "    print('5.작성일자:',bdate)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if no == cnt :\n",
    "        break\n",
    "        \n",
    "    no += 1\n",
    "\n",
    "# 출력 결과를 표(데이터 프레임) 형태로 만들기\n",
    "\n",
    "naver_blog = pd.DataFrame()\n",
    "naver_blog['번호'] = no2\n",
    "naver_blog['제목'] = title2\n",
    "naver_blog['작성자'] = writer2\n",
    "naver_blog['요약내용'] = contents2\n",
    "naver_blog['작성일자'] = bdate2\n",
    "\n",
    "# 저장될 파일위치와 이름을 지정합니다\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "sec_name = 'Naver_View'\n",
    "os.makedirs(f_dir+s+'-'+query_txt+'-'+sec_name)\n",
    "os.chdir(f_dir+s+'-'+query_txt+'-'+sec_name)\n",
    "\n",
    "fc_name=f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+s+'-'+query_txt+'-'+sec_name+'.csv'\n",
    "fx_name=f_dir+s+'-'+query_txt+'-'+sec_name+'\\\\'+s+'-'+query_txt+'-'+sec_name+'.xls'\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "naver_blog.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "print(\" csv 파일 저장 경로: %s\" %fc_name) \n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "import openpyxl\n",
    "naver_blog.to_excel(fx_name , index=False, engine='openpyxl')\n",
    "print(\" xls 파일 저장 경로: %s\" %fx_name) \n",
    "\n",
    "# 엑셀파일 실행하기\n",
    "import win32com.client as win32   #pywin32 , pypiwin32 설치후 동작\n",
    "import win32api  #파이썬 프롬프트를 관리자 권한으로 실행해야 에러없음\n",
    "                 #파이썬 쉘을 관리자 권한으로 실행한 후 불러오기로 이 소스 실행하기\n",
    "\n",
    "excel = win32.Dispatch('Excel.Application')\n",
    "wb = excel.Workbooks.Open(fx_name)\n",
    "sheet = wb.ActiveSheet\n",
    "excel.ActiveWorkbook.Save()\n",
    "excel.Visible=True\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lesson 3.국내 여행 키워드 분석\n",
    "#Step 1. 필요한 모듈을 실행합니다.\n",
    "from konlpy.tag import *        #pip install konlpy 먼저 하세요\n",
    "import matplotlib.pyplot as plt #pip install matplotlib 먼저 하세요\n",
    "from matplotlib import font_manager , rc\n",
    "from wordcloud import WordCloud  # pip install wordcloud 먼저 하세요\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma( )\n",
    "\n",
    "#Step 2 . 텍스트 파일을 불러와서 형태소 분석을 합니다.\n",
    "data1 = open(fc_name,encoding=\"UTF-8\").read( )\n",
    "data1 = contents2\n",
    "\n",
    "#print(data1)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Step 3. 키워드를 추출합니다\n",
    "data2=[]\n",
    "for a in data1 :\n",
    "    data2.append( okt.nouns(a) )\n",
    "\n",
    "#Step 4. 추출된 단어들의 빈도를 조사한 후 많이 언급된 100개만 출력합니다\n",
    "print(\"\\n\")\n",
    "data3 = sum(data2, [])\n",
    "data4 = Counter(data3)\n",
    "data5 = data4.most_common(100)\n",
    "\n",
    "#Step 5. 불용어 제거하기\n",
    "sword = open(\"c:\\\\temp\\\\여행gsub.txt\").read()\n",
    "\n",
    "data6 = [ each_word for each_word in data3\n",
    "          if each_word not in sword ]\n",
    "\n",
    "#용어 정리하기\n",
    "data6_1 = [ ]\n",
    "for i in data6 :\n",
    "    if len(i) >= 2 and len(i) <= 10 :\n",
    "        if i == '제주' or i == '제주도' or i=='우도' or i =='애월' :\n",
    "            data6_1.append(i.replace(i,'제주도'))\n",
    "            \n",
    "        elif i == '국내' or i == '대한민국' or i == '한국' :\n",
    "            data6_1.append(i.replace(i,'국내여행'))\n",
    "        elif i == '핑크' or i == '뮬리' or i == '핑크뮬리' :\n",
    "            data6_1.append(i.replace(i,'핑크뮬리'))\n",
    "        elif i == '아이' or i == '어린이' or i == '아기' or i =='키즈':\n",
    "            data6_1.append(i.replace(i,'아이'))\n",
    "        elif i == '엘리' or i == '시안' or i == '강촌':\n",
    "            data6_1.append(i.replace(i,'강촌엘리시안'))\n",
    "        else :\n",
    "                data6_1.append(i)\n",
    "\n",
    "            \n",
    "#Step 6. 글자수로 불용어 제거하기\n",
    "data7 = []\n",
    "for i in data6_1 :\n",
    "    if len(i) >= 2 and len(i) <= 10 :\n",
    "        data7.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. 단어별 빈도수 집계하기\n",
    "data8 = Counter(data7)\n",
    "data9 = data8.most_common(200)\n",
    "print(\"2.단어별 빈도수:\",data9)\n",
    "data10 = dict(data9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data9_2 = pd.DataFrame(data9)\n",
    "data9_3 = data9_2.rename(columns={0:'키워드' , 1:'빈도수'})\n",
    "display(data9_3)\n",
    "data9_3.to_csv('c:\\\\py_temp\\\\가을여행주요키워드.csv' , index=False , encoding='utf-8-sig')\n",
    "data9_10 = data9_3.head(10)\n",
    "display(data9_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#바 차트 그리기 - 상위 10군데만\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "\n",
    "font_location = \"C:\\\\Windows\\\\Fonts\\\\malgun.ttf\"\n",
    "font_name = fm.FontProperties(fname = font_location).get_name()\n",
    "matplotlib.rc('font' , family=font_name)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "x = data9_10['키워드']\n",
    "y = data9_10['빈도수']\n",
    "\n",
    "colors = [np.random.rand(3,) for _ in data9_10['키워드']]\n",
    "\n",
    "plt.bar(x,y , color = colors , width=0.5)\n",
    "plt.title('가을 여행 주요 키워드')\n",
    "plt.ylabel('빈도수(단위:건)')\n",
    "plt.xlabel('키워드')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 8. 워드 클라우드 그리기\n",
    "wordcloud = WordCloud(font_path=\"c:\\\\windows\\\\fonts\\\\HMKMG.TTF\" ,\n",
    "                       relative_scaling=0.4,\n",
    "                       background_color=\"white\"\n",
    "                     ).generate_from_frequencies(data10)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np         # pip install numpy\n",
    "from PIL import Image      # pip install Image\n",
    "from wordcloud import ImageColorGenerator\n",
    "korea = np.array(Image.open(\"c:\\\\data\\\\data\\\\image\\\\heart.jpg\"))\n",
    "wc = WordCloud(font_path=\"c:\\\\windows\\\\fonts\\\\HMKMG.TTF\" ,\n",
    "                       relative_scaling=0.2,mask = korea,\n",
    "                       background_color=\"white\",\n",
    "                       min_font_size=1,\n",
    "                       max_font_size=50,\n",
    "                       max_words=5000\n",
    "                     ).generate_from_frequencies(data10)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korea = np.array(Image.open(\"c:\\\\data\\\\data\\\\image\\\\korea.jpg\"))\n",
    "wc = WordCloud(font_path=\"c:\\\\windows\\\\fonts\\\\HMKMG.TTF\" ,\n",
    "                       relative_scaling=0.2,mask = korea,\n",
    "                       background_color=\"white\",\n",
    "                       min_font_size=1,\n",
    "                       max_font_size=50,\n",
    "                       max_words=5000\n",
    "                     ).generate_from_frequencies(data10)\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "korea = np.array(Image.open(\"c:\\\\data\\\\data\\image\\star.png\"))\n",
    "wc = WordCloud(font_path=\"c:\\\\windows\\\\fonts\\\\HMKMG.TTF\" ,\n",
    "                       relative_scaling=0.2,mask = korea,\n",
    "                       background_color=\"white\",\n",
    "                       min_font_size=1,\n",
    "                       max_font_size=50,\n",
    "                       max_words=5000\n",
    "                     ).generate_from_frequencies(data10)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korea = np.array(Image.open(\"c:\\data\\\\data\\image\\samsung.jpg\"))\n",
    "wc = WordCloud(font_path=\"c:\\\\windows\\\\fonts\\\\HMKMG.TTF\" ,\n",
    "                       relative_scaling=0.2,mask = korea,\n",
    "                       background_color=\"white\",\n",
    "                       min_font_size=1,\n",
    "                       max_font_size=100,\n",
    "                       max_words=5000\n",
    "                     ).generate_from_frequencies(data10)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
